{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bf9d0cf-af14-42ab-95e2-91de1503a1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "input_dir = '../Results/Data/'\n",
    "output_dir = '../Results/Stats/'\n",
    "\n",
    "os.makedirs(output_dir, exist_ok = True) \n",
    "\n",
    "df1 = pd.read_csv(input_dir+'run_conf_0.5.tsv', sep='\\t')\n",
    "df2 = pd.read_csv(input_dir+'run_grad_0.5.tsv', sep='\\t')\n",
    "df3 = pd.read_csv(input_dir+'run_grad01_0.5.tsv', sep='\\t')\n",
    "df4 = pd.read_csv(input_dir+'run_gradinput_0.5.tsv', sep='\\t')\n",
    "df5 = pd.read_csv(input_dir+'run_gradmodel_0.5.tsv', sep='\\t')\n",
    "df6 = pd.read_csv(input_dir+'run_qbc_random_0.5.tsv', sep='\\t')\n",
    "df7 = pd.read_csv(input_dir+'run_hamming_align_0.5.tsv', sep='\\t')\n",
    "\n",
    "frames = [df1, df2, df3, df4, df5, df6, df7]\n",
    "df = pd.concat(frames)\n",
    "\n",
    "df.columns = ['iter', 'binding_ratio', 'exp_num', 'type', 'AgSeq', 'roc_aucs_val',\n",
    "       'roc_aucs_test', 'roc_aucs_testAB', 'roc_aucs_testAG', 'ags_number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5b6c771-dc8f-486b-abb9-0603eb943f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_rel, shapiro, t\n",
    "\n",
    "def calculate_auc(df, r):\n",
    "    return df.groupby(['exp_num', 'type']).apply(lambda x: pd.Series({'auc': x['roc_aucs_' + r].sum()})).reset_index()\n",
    "\n",
    "def ttestf(df, r, alpha = 0.05):\n",
    "    df2 = df.copy()\n",
    "    df2 = df2[['iter', 'exp_num', 'type', 'roc_aucs_'+r]].drop_duplicates()\n",
    "    auc_df2 = calculate_auc(df2, r)\n",
    "    df3_1 = auc_df2[auc_df2.type != 'random']\n",
    "    df3_2 = auc_df2[auc_df2.type == 'random'].drop(columns='type')\n",
    "    \n",
    "    df3 = pd.merge(df3_1, df3_2, on='exp_num', suffixes=('_method', '_random'))\n",
    "    df3.columns = ['exp_num', 'method', 'auc_method', 'auc_random']\n",
    "    num_tests = df3['method'].nunique()\n",
    "\n",
    "    alpha_adjusted = alpha / num_tests\n",
    "    \n",
    "    results = []\n",
    "    norm_results = []\n",
    "    for method in df3['method'].unique():\n",
    "        subset = df3[df3['method'] == method]\n",
    "\n",
    "        differences = subset['auc_method'] - subset['auc_random']\n",
    "    \n",
    "        normality_stat, normality_p_value = shapiro(differences)\n",
    "        normality_pass = normality_p_value > alpha\n",
    "\n",
    "        norm_results.append({\n",
    "        'method': method,\n",
    "        'normality_p_value': normality_p_value,\n",
    "        'normality_pass': normality_pass})\n",
    "        \n",
    "        t_stat, p_value = ttest_rel(subset['auc_method'], subset['auc_random'], alternative='greater')\n",
    "        corrected_p_value = p_value * num_tests\n",
    "        corrected_p_value = min(corrected_p_value, 1.0)\n",
    "        is_significant = corrected_p_value < alpha\n",
    "        mean_diff = differences.mean()\n",
    "        std_diff = differences.std(ddof=1)\n",
    "        n = len(differences)\n",
    "        t_critical = t.ppf(1 - alpha_adjusted, df=n - 1)\n",
    "        margin_of_error = t_critical * (std_diff / np.sqrt(n))\n",
    "        \n",
    "        ci_lower = mean_diff - margin_of_error\n",
    "        ci_upper = np.inf\n",
    "\n",
    "        results.append({\n",
    "            'method': method,\n",
    "            't_stat': t_stat,\n",
    "            'p_value': p_value,\n",
    "            'corrected_p_value': corrected_p_value,\n",
    "            'significant_after_correction': is_significant,\n",
    "            'mean_diff': mean_diff,\n",
    "            'ci_lower': ci_lower,\n",
    "            'ci_upper': ci_upper\n",
    "        })\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    norm_results = pd.DataFrame(norm_results)\n",
    "    return subset['auc_random'], results_df, norm_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52168fc7-7206-4f76-8ee7-3b448cb8bdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = ['test', 'testAB', 'testAG']\n",
    "\n",
    "for alpha in [0.01]:\n",
    "    all_results = []\n",
    "    all_norm_results = []\n",
    "    for r in rs:\n",
    "        auc_random, results_df_r, norm_results = ttestf(df, r, alpha = alpha)\n",
    "        results_df_r['test'] = r\n",
    "        results_df_r['mean_random'] = auc_random.mean()\n",
    "        all_results.append(results_df_r)\n",
    "        all_norm_results.append(norm_results)\n",
    "    \n",
    "    \n",
    "    general_results_df = pd.concat(all_results, ignore_index=True)\n",
    "    general_results_df['mean_diff_rel'] = general_results_df.apply(lambda x: x.mean_diff/x.mean_random, axis=1)\n",
    "    general_results_df['ci_lower_rel'] = general_results_df.apply(lambda x: x.ci_lower/x.mean_random, axis=1)\n",
    "    \n",
    "    general_norm_df = pd.concat(all_norm_results, ignore_index=True)\n",
    "    \n",
    "    general_results_df['method_short'] = general_results_df['method']\n",
    "    \n",
    "    general_results_df['method'] = general_results_df['method'].replace({\n",
    "        'random': 'Random',\n",
    "        'gradient2_max': 'Gradient to input (max)',\n",
    "        'gradient2_av': 'Gradient to input (average)',\n",
    "        'gradient3_max': 'Gradient to model (max)',\n",
    "        'gradient3_av': 'Gradient to model (average)',\n",
    "        'gradient_0': 'Gradient 0-1 (average)',\n",
    "        'gradient_01': 'Gradient 0-1 (max)',\n",
    "        'gradient_av': 'Gradient on last layer (average)',\n",
    "        'gradient_confounding_av': 'Gradient conf. labels (average)',\n",
    "        'gradient_confounding_max': 'Gradient conf. labels (max)',\n",
    "        'gradient_max': 'Gradient on last layer (max)',\n",
    "        'hamming': 'Hamming average distance',\n",
    "        'hamming_min': 'Hamming min distance',\n",
    "        'qbc': 'QBC',\n",
    "        'alignments': 'Alignments average distance'\n",
    "    })\n",
    "    \n",
    "    general_results_df['method_short'] = general_results_df['method_short'].replace({\n",
    "        'random': 'Random',\n",
    "        'gradient2_max': 'Grad-In Max',\n",
    "        'gradient2_av': 'Grad-In Avg',\n",
    "        'gradient3_max': 'Grad-Model Max',\n",
    "        'gradient3_av': 'Grad-Model Avg',\n",
    "        'gradient_0': 'Grad-0-1 Avg',\n",
    "        'gradient_01': 'Grad-0-1 Max',\n",
    "        'gradient_av': 'Grad-Last Avg',\n",
    "        'gradient_confounding_av': 'Grad-Conf Avg',\n",
    "        'gradient_confounding_max': 'Grad-Conf Max',\n",
    "        'gradient_max': 'Grad-Last Max',\n",
    "        'hamming': 'Hamming Avg',\n",
    "        'hamming_min': 'Hamming Min',\n",
    "        'qbc': 'QBC',\n",
    "        'alignments': 'Align Avg Dist'\n",
    "    })\n",
    "    \n",
    "    general_results_df = general_results_df[['test', 'method', 'method_short', 't_stat', 'p_value', 'corrected_p_value',\n",
    "           'significant_after_correction', 'mean_diff', 'ci_lower', 'ci_upper', 'mean_random', \n",
    "           'mean_diff_rel', 'ci_lower_rel']]\n",
    "    \n",
    "    \n",
    "    with pd.ExcelWriter(f'{output_dir}stat_{alpha}.xlsx', engine='openpyxl') as writer:\n",
    "        general_results_df.to_excel(writer, index=False, sheet_name='Results')\n",
    "        general_norm_df.to_excel(writer, index=False, sheet_name='Normality Test Results')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
